{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upgrading our MNIST Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I: 10 Train accuracy: 0.432 Test-Acc:: 0.5506\n",
      "I: 20 Train accuracy: 0.591 Test-Acc:: 0.6536\n",
      "I: 30 Train accuracy: 0.652 Test-Acc:: 0.706\n",
      "I: 40 Train accuracy: 0.681 Test-Acc:: 0.7361\n",
      "I: 50 Train accuracy: 0.705 Test-Acc:: 0.7611\n",
      "I: 60 Train accuracy: 0.725 Test-Acc:: 0.7816\n",
      "I: 70 Train accuracy: 0.737 Test-Acc:: 0.7941\n",
      "I: 80 Train accuracy: 0.743 Test-Acc:: 0.8035\n",
      "I: 90 Train accuracy: 0.765 Test-Acc:: 0.811\n",
      "I: 100 Train accuracy: 0.781 Test-Acc:: 0.8164\n",
      "I: 110 Train accuracy: 0.778 Test-Acc:: 0.8225\n",
      "I: 120 Train accuracy: 0.787 Test-Acc:: 0.8272\n",
      "I: 130 Train accuracy: 0.782 Test-Acc:: 0.8314\n",
      "I: 140 Train accuracy: 0.788 Test-Acc:: 0.834\n",
      "I: 150 Train accuracy: 0.792 Test-Acc:: 0.8367\n",
      "I: 160 Train accuracy: 0.802 Test-Acc:: 0.8406\n",
      "I: 170 Train accuracy: 0.802 Test-Acc:: 0.8435\n",
      "I: 180 Train accuracy: 0.801 Test-Acc:: 0.8459\n",
      "I: 190 Train accuracy: 0.811 Test-Acc:: 0.8474\n",
      "I: 200 Train accuracy: 0.81 Test-Acc:: 0.8481\n",
      "I: 210 Train accuracy: 0.805 Test-Acc:: 0.8498\n",
      "I: 220 Train accuracy: 0.817 Test-Acc:: 0.8514\n",
      "I: 230 Train accuracy: 0.828 Test-Acc:: 0.8527\n",
      "I: 240 Train accuracy: 0.818 Test-Acc:: 0.8548\n",
      "I: 250 Train accuracy: 0.818 Test-Acc:: 0.8558\n",
      "I: 260 Train accuracy: 0.816 Test-Acc:: 0.8587\n",
      "I: 270 Train accuracy: 0.813 Test-Acc:: 0.86\n",
      "I: 280 Train accuracy: 0.824 Test-Acc:: 0.861\n",
      "I: 290 Train accuracy: 0.824 Test-Acc:: 0.8621\n",
      "I: 300 Train accuracy: 0.82 Test-Acc:: 0.8625\n"
     ]
    }
   ],
   "source": [
    "using MLDatasets\n",
    "train_x, train_y = MNIST.traindata()\n",
    "test_x,  test_y  = MNIST.testdata();\n",
    "\n",
    "(images, labels) = (reshape(train_x[:,:,1:1000], (28*28, 1000)), train_y[1:1000])\n",
    "one_hot_labels = zeros(10,length(labels))\n",
    "for (i,l) in enumerate(labels)\n",
    "    one_hot_labels[l+1, i] = 1.0\n",
    "end\n",
    "labels = one_hot_labels\n",
    "\n",
    "test_images = reshape(test_x, (28*28, size(test_x,3)))\n",
    "test_labels = zeros((10, size(test_x,3)))\n",
    "\n",
    "for (i,l) in enumerate(test_y)\n",
    "    test_labels[l+1, i] = 1.0\n",
    "end\n",
    "\n",
    "using Random\n",
    "Random.seed!(1)\n",
    "\n",
    "tanh2deriv(output) = 1 - output^2\n",
    "\n",
    "function softmax(x)\n",
    "    temp = exp.(x)\n",
    "    return temp ./ sum(temp, dims=2)\n",
    "end\n",
    "\n",
    "alpha, iterations, hidden_size = (2, 300, 100)\n",
    "pixels_per_image, num_labels = (784, 10)\n",
    "batch_size = 100\n",
    "\n",
    "weights_0_1 = 0.2 .* rand(pixels_per_image,hidden_size) .- 0.1\n",
    "weights_1_2 = 0.2 .* rand(hidden_size,num_labels) .- 0.1\n",
    "\n",
    "for j = 1:iterations\n",
    "    Error, Correct_cnt = (0.0, 0)\n",
    "    \n",
    "    for i = 1:batch_size:size(images, 2)-batch_size\n",
    "        batch_start, batch_end = i, i+batch_size-1\n",
    "        layer_0 = images[:, batch_start:batch_end]\n",
    "        layer_1 = tanh.(layer_0' * weights_0_1)\n",
    "        dropout_mask = bitrand(size(layer_1))\n",
    "        layer_1 .*= (dropout_mask .* 2)\n",
    "        layer_2 = softmax(layer_1 * weights_1_2)\n",
    "        \n",
    "        Error += sum((labels[:, batch_start:batch_end]' .- layer_2) .^ 2)\n",
    "        \n",
    "        for k=1:batch_size\n",
    "            Correct_cnt += Int(argmax(layer_2[k, :]) == argmax(labels[:, batch_start+k-1]))\n",
    "        end\n",
    "        layer_2_delta = (labels[:, batch_start:batch_end]' .- layer_2) ./ (batch_size * size(layer_2)[1])\n",
    "        layer_1_delta = (layer_2_delta * weights_1_2') .* tanh2deriv.(layer_1)\n",
    "\n",
    "        layer_1_delta .*= dropout_mask\n",
    "\n",
    "        weights_1_2 += alpha .* layer_1' * layer_2_delta\n",
    "        weights_0_1 += alpha .* layer_0 * layer_1_delta\n",
    "        \n",
    "    end\n",
    "        \n",
    "    if (j % 10 == 0)\n",
    "        test_Error, test_Correct_cnt = (0.0, 0)\n",
    "        for i = 1:size(test_images, 2)\n",
    "            layer_0 = test_images[:, i]\n",
    "            layer_1 = tanh.(layer_0' * weights_0_1)\n",
    "            layer_2 = layer_1 * weights_1_2\n",
    "\n",
    "            test_Error += sum((test_labels[:, i]' .- layer_2) .^ 2)\n",
    "            test_Correct_cnt += Int(argmax(layer_2[1,:]) == argmax(test_labels[:, i]))\n",
    "        end\n",
    "        println(\"I: $(j) Train accuracy: $(Correct_cnt/size(images, 2)) Test-Acc:: $(test_Correct_cnt/size(test_images, 2))\")\n",
    "    end\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.0",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
